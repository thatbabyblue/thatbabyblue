<!-- Centered banner/logo (optional) -->
<p align="center">
  <img src="assets/logo.png" alt="Logo" width="180">
</p>

<h1 align="center">Hi, I'm Sean ğŸ‘‹</h1>
<p align="center">
  Deep Learning & LLMs Enthusiast
</p>

---

## âš“ï¸ What Iâ€™m About

Who would have thought some dabbling with LLMs, deep learning stuff has become some ongoing interest. I've built and refined **LLM-powered systems**â€”from training tiny character-level GPTs, wiring up **inference pipelines**, **fine-tuning**, and **tool use/agents** for real apps to creating an AI job search agent. Researching into recent development of LLMs, I also discovered the potential bottleneck of text-based generative models architecture. I found out there's this other architecture, namely world model, has been making some headlines. Google DeepMind recently released [**Genie 3**](https://deepmind.google/discover/blog/genie-3-a-new-frontier-for-world-models/), which is based on this architecture. I'm exploring more towards that direction.    

---

## ğŸ§  Deep Learning & LLMs

- **Training/Fine-Tuning**: GPT-style Transformers
- **Inference/Serving**: vLLM, TGI, TensorRT-LLM, quantization (INT8/4), KV-cache tuning
- **Data & Evals**: dataset prep
- **Tooling**: PyTorch

**Recent highlights**
- Built a **MiniGPT** (char-level) from scratch in PyTorch, trained on Shakespeare then fine-tuned on modern English (sampling, top-k/top-p, temperature).
- Implemented a **clean training loop** with gradient clipping, eval cycles, and checkpointing.
- Added **generate.py** with stable inference and safety knobs (temperature/top-k).

---

## ğŸ› ï¸ Developer Toolkit

**Languages**
- Python â€¢ Java â€¢ C++ â€¢ Bash

**Frameworks/Libs**
- PyTorch â€¢ Transformers â€¢ numpy

**Systems/DevOps**
- Docker â€¢ Linux

**Data/Storage**
- Pandas

---

## ğŸ§ª Featured Projects

### ğŸ”¹ MiniGPT â€“ Character-Level Transformer
Train-from-scratch GPT with multi-head causal attention, GELU MLPs, layernorm, and sampling.
- **Tech**: PyTorch, Transformers
- **Highlights**: clean generation API, top-k, temperature, gradient clipping
- Repo: `thatbabyblue/GPTmini`


## ğŸ—ºï¸ What Iâ€™m Exploring Next

- **Agent frameworks** (tool use, planning), reliability in prod
- **World Models** its theory and its state-of-the-art applications

---

## ğŸ“« Get in Touch

- GitHub: <a href="https://github.com/thatbabyblue">@thatbabyblue</a>  
- (Add your LinkedIn/Twitter/Email here)

---


<sub>Built with â¤ï¸ for deep learning, clean code, and shipping useful things.</sub>

